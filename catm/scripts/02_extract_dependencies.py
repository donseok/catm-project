#!/usr/bin/env python3
"""
02_extract_dependencies.py - COBOL ì˜ì¡´ì„± ì¶”ì¶œ

ì •ì  ë¶„ì„ìœ¼ë¡œ ë‹¤ìŒì„ ì¶”ì¶œí•©ë‹ˆë‹¤:
- CALL ê´€ê³„ (í”„ë¡œê·¸ë¨ â†’ í”„ë¡œê·¸ë¨)
- COPY ê´€ê³„ (í”„ë¡œê·¸ë¨ â†’ COPYBOOK)
- DB2 í…Œì´ë¸” ì°¸ì¡° (í”„ë¡œê·¸ë¨ â†’ DB2)
- VSAM íŒŒì¼ ì°¸ì¡° (í”„ë¡œê·¸ë¨ â†’ VSAM)
- JCL ì‹¤í–‰ ìˆœì„œ (JOB â†’ STEP â†’ PGM)
- McCabe ë³µì¡ë„ (ê·¼ì‚¬ì¹˜)

ì‚¬ìš©ë²•:
    python catm/scripts/02_extract_dependencies.py
"""

import sys
import os
import re

# pip install -e . ë¡œ ì„¤ì¹˜ë˜ì§€ ì•Šì€ í™˜ê²½ì„ ìœ„í•œ í´ë°±
if __name__ == "__main__":
    sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.dirname(__file__))))

from pathlib import Path
from datetime import datetime
from catm.utils.cobol_parser import analyze_program
from catm.utils.file_utils import load_config, save_json, find_files


def analyze_jcl(file_path: str) -> dict:
    """JCL íŒŒì¼ ë¶„ì„ - ë°°ì¹˜ ì‹¤í–‰ ìˆœì„œ ì¶”ì¶œ"""
    with open(file_path, "r", encoding="utf-8", errors="ignore") as f:
        source = f.read()
    
    job_name = Path(file_path).stem.upper()
    
    # EXEC PGM= ì¶”ì¶œ
    steps = []
    step_pattern = r"//(\w+)\s+EXEC\s+(?:PGM=)?(\w+)"
    for match in re.finditer(step_pattern, source, re.IGNORECASE):
        step_name, pgm_name = match.groups()
        steps.append({
            "step": step_name.upper(),
            "program": pgm_name.upper(),
        })
    
    # DD DSN= ì¶”ì¶œ
    datasets = []
    dd_pattern = r"//(\w+)\s+DD\s+(?:DSN|DSNAME)=([^,\s]+)"
    for match in re.finditer(dd_pattern, source, re.IGNORECASE):
        dd_name, dsn = match.groups()
        datasets.append({
            "dd": dd_name.upper(),
            "dsn": dsn,
        })
    
    return {
        "job_name": job_name,
        "file_path": file_path,
        "steps": steps,
        "datasets": datasets,
        "step_count": len(steps),
    }


def build_category_map(config: dict) -> dict[str, str]:
    """í”„ë¡œê·¸ë¨ëª… â†’ ì¹´í…Œê³ ë¦¬ëª… ë§¤í•‘ ë”•ì…”ë„ˆë¦¬ ìƒì„±"""
    cat_map: dict[str, str] = {}
    for cat in config.get("program_categories", []):
        for pgm in cat.get("programs", []):
            cat_map[pgm.upper()] = cat["name"]
    return cat_map


def main():
    print("=" * 50)
    print("  CATM Step 2: ì˜ì¡´ì„± ì¶”ì¶œ (ì •ì  ë¶„ì„)")
    print("=" * 50)

    config = load_config()
    source_root = config["paths"]["source_root"]
    output_root = config["paths"]["output_root"]
    category_map = build_category_map(config)

    result = {
        "programs": [],
        "jcl_jobs": [],
        "summary": {},
        "categories_summary": [],
        "scan_date": datetime.now().isoformat(),
    }
    
    # --- COBOL í”„ë¡œê·¸ë¨ ë¶„ì„ ---
    cobol_dir = os.path.join(source_root, config["source_dirs"]["cobol"])
    cobol_files = find_files(cobol_dir, config["file_extensions"]["cobol"])
    
    print(f"\n  ğŸ“‚ COBOL í”„ë¡œê·¸ë¨ ë¶„ì„: {len(cobol_files)}ê°œ")
    for f in cobol_files:
        print(f"    ë¶„ì„ ì¤‘: {f.stem.upper()}", end="")
        try:
            pgm = analyze_program(str(f))
            result["programs"].append({
                "name": pgm.name,
                "file_path": pgm.file_path,
                "line_count": pgm.line_count,
                "program_id": pgm.program_id,
                "calls": pgm.calls,
                "copies": pgm.copies,
                "db2_tables": pgm.db2_tables,
                "vsam_files": pgm.vsam_files,
                "cics_maps": pgm.cics_maps,
                "complexity": pgm.complexity,
                "paragraph_count": pgm.paragraph_count,
                "has_cics": pgm.has_cics,
                "has_db2": pgm.has_db2,
                "has_vsam": pgm.has_vsam,
                "category": category_map.get(pgm.name, "ë¯¸ë¶„ë¥˜"),
            })
            print(f" âœ… (CALL:{len(pgm.calls)}, COPY:{len(pgm.copies)}, "
                  f"DB2:{len(pgm.db2_tables)}, ë³µì¡ë„:{pgm.complexity})")
        except Exception as e:
            print(f" âŒ ì—ëŸ¬: {e}")
    
    # --- JCL ë¶„ì„ ---
    jcl_dir = os.path.join(source_root, config["source_dirs"]["jcl"])
    jcl_files = find_files(jcl_dir, config["file_extensions"]["jcl"])
    
    print(f"\n  ğŸ“‚ JCL ë¶„ì„: {len(jcl_files)}ê°œ")
    for f in jcl_files:
        print(f"    ë¶„ì„ ì¤‘: {f.stem.upper()}", end="")
        try:
            jcl = analyze_jcl(str(f))
            result["jcl_jobs"].append(jcl)
            print(f" âœ… ({jcl['step_count']} steps)")
        except Exception as e:
            print(f" âŒ ì—ëŸ¬: {e}")
    
    # --- ìš”ì•½ í†µê³„ ---
    programs = result["programs"]
    result["summary"] = {
        "total_programs": len(programs),
        "total_lines": sum(p["line_count"] for p in programs),
        "total_jcl_jobs": len(result["jcl_jobs"]),
        "avg_complexity": (
            round(sum(p["complexity"] for p in programs) / len(programs), 1)
            if programs else 0
        ),
        "max_complexity": max((p["complexity"] for p in programs), default=0),
        "unique_copybooks": len(set(c for p in programs for c in p["copies"])),
        "unique_db2_tables": len(set(t for p in programs for t in p["db2_tables"])),
        "unique_vsam_files": len(set(v for p in programs for v in p["vsam_files"])),
        "cics_programs": sum(1 for p in programs if p["has_cics"]),
        "db2_programs": sum(1 for p in programs if p["has_db2"]),
        "vsam_programs": sum(1 for p in programs if p["has_vsam"]),
    }
    
    # --- ì¹´í…Œê³ ë¦¬ë³„ ìš”ì•½ ---
    cat_groups: dict[str, list] = {}
    for p in programs:
        cat = p.get("category", "ë¯¸ë¶„ë¥˜")
        cat_groups.setdefault(cat, []).append(p)

    result["categories_summary"] = [
        {
            "name": cat_name,
            "program_count": len(progs),
            "total_lines": sum(p["line_count"] for p in progs),
            "avg_complexity": (
                round(sum(p["complexity"] for p in progs) / len(progs), 1)
                if progs else 0
            ),
            "programs": [p["name"] for p in progs],
        }
        for cat_name, progs in cat_groups.items()
    ]

    # ì €ì¥
    json_path = os.path.join(output_root, "reports", "dependency-scan.json")
    save_json(result, json_path)
    
    # ìš”ì•½ ì¶œë ¥
    s = result["summary"]
    print(f"\n{'=' * 50}")
    print(f"  ì˜ì¡´ì„± ì¶”ì¶œ ì™„ë£Œ!")
    print(f"  í”„ë¡œê·¸ë¨: {s['total_programs']}ê°œ ({s['total_lines']:,} ë¼ì¸)")
    print(f"  JCL: {s['total_jcl_jobs']}ê°œ")
    print(f"  COPYBOOK: {s['unique_copybooks']}ê°œ (ê³ ìœ )")
    print(f"  DB2 í…Œì´ë¸”: {s['unique_db2_tables']}ê°œ (ê³ ìœ )")
    print(f"  í‰ê·  ë³µì¡ë„: {s['avg_complexity']}")
    print(f"  CICS ì‚¬ìš©: {s['cics_programs']}ê°œ / DB2 ì‚¬ìš©: {s['db2_programs']}ê°œ")
    print(f"  ê²°ê³¼: {json_path}")
    print(f"{'=' * 50}")


if __name__ == "__main__":
    main()
